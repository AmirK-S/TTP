---
phase: 02-transcription-pipeline
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src-tauri/Cargo.toml
  - src-tauri/src/transcription/mod.rs
  - src-tauri/src/transcription/whisper.rs
  - src-tauri/src/transcription/polish.rs
  - src-tauri/capabilities/default.json
autonomous: true
user_setup:
  - service: openai
    why: "Transcription and polish APIs"
    env_vars: []
    dashboard_config: []
    notes: "API key already configured in Phase 1 via keychain"

must_haves:
  truths:
    - "Audio file can be sent to OpenAI transcription API"
    - "Transcription returns text with punctuation"
    - "Raw transcription can be polished by GPT-4o-mini"
    - "Filler words are removed from polished text"
    - "Self-corrections are resolved to final choice"
  artifacts:
    - path: "src-tauri/src/transcription/mod.rs"
      provides: "Module exports for transcription subsystem"
      exports: ["transcribe_audio", "polish_text"]
    - path: "src-tauri/src/transcription/whisper.rs"
      provides: "OpenAI gpt-4o-transcribe API client"
      contains: "multipart::Form"
      min_lines: 40
    - path: "src-tauri/src/transcription/polish.rs"
      provides: "GPT-4o-mini text cleanup"
      contains: "POLISH_SYSTEM_PROMPT"
      min_lines: 60
  key_links:
    - from: "src-tauri/src/transcription/whisper.rs"
      to: "https://api.openai.com/v1/audio/transcriptions"
      via: "reqwest multipart POST"
      pattern: "api.openai.com.*transcriptions"
    - from: "src-tauri/src/transcription/polish.rs"
      to: "https://api.openai.com/v1/chat/completions"
      via: "reqwest JSON POST"
      pattern: "api.openai.com.*chat/completions"
---

<objective>
Create the transcription and polish backend modules that call OpenAI APIs.

Purpose: These modules handle the core AI processing — converting audio to text and cleaning up the transcription. They are the foundation of the transcription pipeline.

Output: Two Rust modules (whisper.rs, polish.rs) that can transcribe audio files and polish text, with proper error handling and retries.
</objective>

<execution_context>
@/Users/amirkellousidhoum/.claude/get-shit-done/workflows/execute-plan.md
@/Users/amirkellousidhoum/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-transcription-pipeline/02-RESEARCH.md
@.planning/phases/02-transcription-pipeline/02-CONTEXT.md
@src-tauri/src/lib.rs
@src-tauri/src/credentials.rs
@src-tauri/Cargo.toml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add HTTP dependencies and create transcription module structure</name>
  <files>
    src-tauri/Cargo.toml
    src-tauri/src/transcription/mod.rs
    src-tauri/capabilities/default.json
  </files>
  <action>
Add required dependencies to Cargo.toml:
- `tauri-plugin-http` with reqwest feature (for HTTP client with multipart support)
- `tokio` with rt-multi-thread and macros features (for async runtime)

Create `src-tauri/src/transcription/mod.rs` that exports the submodules:
```rust
pub mod whisper;
pub mod polish;

pub use whisper::transcribe_audio;
pub use polish::polish_text;
```

Update `src-tauri/capabilities/default.json` to add HTTP permission for OpenAI API:
```json
{
  "identifier": "http:default",
  "allow": [
    { "url": "https://api.openai.com/*" }
  ]
}
```

Also add the plugin to lib.rs setup (just the plugin init, not the commands yet).

Do NOT use tauri-plugin-upload — use reqwest multipart directly for better control.
  </action>
  <verify>
`cargo check` passes with new dependencies. The transcription module structure exists.
  </verify>
  <done>
Dependencies added, module structure created, HTTP capability configured for OpenAI API.
  </done>
</task>

<task type="auto">
  <name>Task 2: Implement Whisper transcription API client</name>
  <files>
    src-tauri/src/transcription/whisper.rs
  </files>
  <action>
Create `src-tauri/src/transcription/whisper.rs` with:

1. Constant for OpenAI transcription URL: `https://api.openai.com/v1/audio/transcriptions`

2. Async function `transcribe_audio(api_key: &str, audio_path: &str) -> Result<String, String>`:
   - Read audio file bytes from disk
   - Create multipart form with:
     - `model`: "gpt-4o-transcribe" (NOT whisper-1 — research says gpt-4o-transcribe is better)
     - `response_format`: "text"
     - `file`: audio bytes as Part with filename "recording.wav" and mime "audio/wav"
   - POST to OpenAI with Authorization header
   - Implement retry logic: 3 attempts with 500ms, 1000ms, 1500ms delays (exponential backoff)
   - 30 second timeout per request
   - Return transcription text on success

Error handling:
- File read errors: "Failed to read audio file: {error}"
- HTTP errors: "Transcription API error: {status}"
- Network errors: "Transcription request failed: {error}"
- Parse errors: "Failed to read transcription response: {error}"

Use `tauri_plugin_http::reqwest` (not standalone reqwest) for Tauri integration.
  </action>
  <verify>
`cargo check` passes. Function signature matches expected interface.
  </verify>
  <done>
Whisper API client implemented with multipart upload, gpt-4o-transcribe model, and retry logic.
  </done>
</task>

<task type="auto">
  <name>Task 3: Implement GPT-4o-mini polish API client</name>
  <files>
    src-tauri/src/transcription/polish.rs
  </files>
  <action>
Create `src-tauri/src/transcription/polish.rs` with:

1. Constant for OpenAI chat URL: `https://api.openai.com/v1/chat/completions`

2. System prompt constant (POLISH_SYSTEM_PROMPT) based on CONTEXT.md decisions:
```
You are a transcription editor. Your job is to clean up voice transcriptions while preserving the speaker's voice and intent.

Rules:
1. Remove ALL filler words: um, uh, like (when used as filler), you know, sort of, kind of, basically, literally (when meaningless)
2. Fix obvious grammar errors but preserve casual speech patterns — do NOT make casual speech formal
3. Add proper punctuation and capitalization (periods, commas, question marks)
4. Handle self-corrections: when someone says "Tuesday no wait Wednesday" or "Send it Monday. Actually make that Tuesday", keep ONLY the final corrected version
5. Preserve the speaker's exact tone — don't elevate formality
6. If uncertain whether something is a correction, preserve the original verbatim

Return ONLY the cleaned text, nothing else.
```

3. Request/response structs (serde):
   - ChatRequest { model, messages, temperature, max_tokens }
   - ChatMessage { role, content }
   - ChatResponse { choices: Vec<ChatChoice> }
   - ChatChoice { message: ChatMessageResponse }
   - ChatMessageResponse { content }

4. Async function `polish_text(api_key: &str, raw_text: &str) -> Result<String, String>`:
   - Create ChatRequest with:
     - model: "gpt-4o-mini"
     - temperature: 0.3 (low for consistency, per research)
     - max_tokens: 1024
     - messages: [system prompt, user message with raw_text]
   - POST JSON to OpenAI
   - Implement retry logic: 3 attempts with exponential backoff
   - 15 second timeout per request
   - Parse response and extract content from first choice
   - Trim whitespace from result

Error handling:
- HTTP errors: "Polish API error: {status}"
- Network errors: "Polish request failed: {error}"
- Parse errors: "Failed to parse polish response: {error}"
- Empty response: "Empty response from polish API"
  </action>
  <verify>
`cargo check` passes. System prompt matches CONTEXT.md requirements.
  </verify>
  <done>
GPT-4o-mini polish client implemented with structured prompt for filler removal, grammar fixes, and self-correction handling.
  </done>
</task>

</tasks>

<verification>
All verification for this plan:

1. `cargo check` passes with no errors
2. `src-tauri/src/transcription/` directory exists with mod.rs, whisper.rs, polish.rs
3. Cargo.toml contains tauri-plugin-http and tokio dependencies
4. capabilities/default.json has HTTP permission for api.openai.com
5. System prompt in polish.rs matches CONTEXT.md decisions (filler removal, self-correction, preserve tone)
</verification>

<success_criteria>
- Transcription module can send audio to OpenAI and receive text
- Polish module can clean transcription with GPT-4o-mini
- Both modules have proper retry logic and error handling
- No manual testing required — this is backend infrastructure
</success_criteria>

<output>
After completion, create `.planning/phases/02-transcription-pipeline/02-01-SUMMARY.md`
</output>
