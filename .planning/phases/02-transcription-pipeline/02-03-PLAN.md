---
phase: 02-transcription-pipeline
plan: 03
type: execute
wave: 2
depends_on: ["02-01", "02-02"]
files_modified:
  - src-tauri/src/transcription/pipeline.rs
  - src-tauri/src/transcription/mod.rs
  - src-tauri/src/shortcuts.rs
  - src-tauri/src/lib.rs
  - src/windows/FloatingBar.tsx
  - src/hooks/useTranscription.ts
autonomous: false

must_haves:
  truths:
    - "Recording stop triggers transcription pipeline"
    - "Pipeline stages emit progress events to frontend"
    - "Floating bar shows processing state during transcription"
    - "Successful paste returns to idle state"
    - "Failed paste shows notification with clipboard fallback"
  artifacts:
    - path: "src-tauri/src/transcription/pipeline.rs"
      provides: "Orchestration of transcribe -> polish -> paste"
      contains: "process_recording"
      min_lines: 50
    - path: "src/hooks/useTranscription.ts"
      provides: "Frontend hook for transcription progress"
      contains: "transcription-progress"
      min_lines: 20
    - path: "src/windows/FloatingBar.tsx"
      provides: "Visual feedback during processing"
      contains: "Processing"
  key_links:
    - from: "src-tauri/src/shortcuts.rs"
      to: "src-tauri/src/transcription/pipeline.rs"
      via: "process_recording call on stop"
      pattern: "process_recording"
    - from: "src-tauri/src/transcription/pipeline.rs"
      to: "frontend"
      via: "emit transcription-progress events"
      pattern: "emit.*transcription-progress"
    - from: "src/windows/FloatingBar.tsx"
      to: "src/hooks/useTranscription.ts"
      via: "useTranscription hook"
      pattern: "useTranscription"
---

<objective>
Wire the transcription pipeline together and integrate with the recording flow.

Purpose: This plan connects all the pieces — when recording stops, the pipeline runs (transcribe -> polish -> paste) and the UI shows progress. This completes the core transcription feature.

Output: Complete end-to-end flow: User speaks -> Recording stops -> Transcription -> Polish -> Auto-paste (or clipboard fallback with notification).
</objective>

<execution_context>
@/Users/amirkellousidhoum/.claude/get-shit-done/workflows/execute-plan.md
@/Users/amirkellousidhoum/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-transcription-pipeline/02-RESEARCH.md
@.planning/phases/02-transcription-pipeline/02-CONTEXT.md
@.planning/phases/02-transcription-pipeline/02-01-SUMMARY.md
@.planning/phases/02-transcription-pipeline/02-02-SUMMARY.md
@src-tauri/src/lib.rs
@src-tauri/src/shortcuts.rs
@src-tauri/src/state.rs
@src-tauri/src/recording.rs
@src-tauri/src/credentials.rs
@src/windows/FloatingBar.tsx
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create pipeline orchestration module</name>
  <files>
    src-tauri/src/transcription/pipeline.rs
    src-tauri/src/transcription/mod.rs
    src-tauri/src/credentials.rs
  </files>
  <action>
Create `src-tauri/src/transcription/pipeline.rs`:

1. Import dependencies:
   - crate::credentials for API key access
   - crate::paste for clipboard and paste simulation
   - crate::state for AppState and RecordingState
   - super::{transcribe_audio, polish_text}
   - tauri::{AppHandle, Emitter, Manager}
   - tauri_plugin_notification::NotificationExt

2. Progress event struct:
```rust
#[derive(Clone, serde::Serialize)]
pub struct TranscriptionProgress {
    pub stage: String,  // "transcribing", "polishing", "pasting", "complete", "error"
    pub message: String,
}
```

3. Main function `process_recording(app: &AppHandle, audio_path: String) -> Result<String, String>`:

   a. Set state to Processing and emit progress

   b. Get API key from credentials (add internal getter to credentials.rs that doesn't require command context):
      - If no key, emit error, return Err

   c. Stage 1 - Transcribe:
      - Emit ("transcribing", "Transcribing...")
      - Call transcribe_audio(api_key, audio_path)
      - If empty result, notify "No speech detected", return Err

   d. Stage 2 - Polish:
      - Emit ("polishing", "Processing...")
      - Call polish_text(api_key, raw_text)
      - On error, log and use raw_text as fallback (per CONTEXT.md)

   e. Stage 3 - Paste:
      - Emit ("pasting", "")
      - Create ClipboardGuard to save original
      - Write polished text to clipboard (ALWAYS — backup per CONTEXT.md)
      - Check accessibility permission
      - If permission OK, try simulate_paste()
      - If paste succeeds: wait 150ms, restore clipboard, emit ("complete", "")
      - If paste fails OR no permission: notify "Text copied — paste with Cmd+V", emit ("complete", "")

   f. Set state back to Idle

   g. Return polished text

4. Helper function `emit_progress(app: &AppHandle, stage: &str, message: &str)`

5. Helper function `notify(app: &AppHandle, message: &str)` using notification plugin

Update `src-tauri/src/transcription/mod.rs` to export pipeline:
```rust
pub mod pipeline;
pub use pipeline::process_recording;
```

Update `src-tauri/src/credentials.rs` to add internal getter:
```rust
pub fn get_api_key_internal(app: &AppHandle) -> Result<Option<String>, String> {
    app.keyring()
        .get_password(SERVICE_NAME, API_KEY_USER)
        .map_err(|e| e.to_string())
}
```
  </action>
  <verify>
`cargo check` passes. pipeline.rs has process_recording function with all stages.
  </verify>
  <done>
Pipeline orchestration complete with transcribe -> polish -> paste flow, progress events, and notification fallback.
  </done>
</task>

<task type="auto">
  <name>Task 2: Hook pipeline into recording flow</name>
  <files>
    src-tauri/src/shortcuts.rs
    src-tauri/src/lib.rs
    src-tauri/src/recording.rs
  </files>
  <action>
Update `src-tauri/src/shortcuts.rs`:

1. Import:
   - `crate::recording::{generate_recording_path, RecordingContext}`
   - `crate::transcription::process_recording`

2. Modify `start_recording()`:
   - Generate recording path using generate_recording_path(app)
   - Store path in RecordingContext
   - Start mic-recorder plugin recording to that path:
     ```rust
     use tauri_plugin_mic_recorder::MicRecorder;
     app.mic_recorder().start_recording(path.to_str().unwrap());
     ```

3. Modify `stop_recording()`:
   - Stop mic-recorder:
     ```rust
     app.mic_recorder().stop_recording();
     ```
   - Get audio path from RecordingContext
   - Set state to Processing (not Idle yet)
   - Spawn async task to run pipeline:
     ```rust
     let app_clone = app.clone();
     let path = audio_path.clone();
     tauri::async_runtime::spawn(async move {
         match process_recording(&app_clone, path).await {
             Ok(text) => println!("Transcription complete: {} chars", text.len()),
             Err(e) => eprintln!("Transcription failed: {}", e),
         }
     });
     ```

Update `src-tauri/src/lib.rs`:
- Add `mod transcription;` and `mod paste;` declarations
- Register plugins: clipboard-manager, notification, http

Update `src-tauri/src/recording.rs`:
- Add method to RecordingContext for getting/setting current_file
  </action>
  <verify>
`cargo check` passes. Recording start/stop now triggers mic-recorder and pipeline.
  </verify>
  <done>
Recording flow integrated: start -> mic-recorder starts -> stop -> mic-recorder stops -> pipeline runs async.
  </done>
</task>

<task type="auto">
  <name>Task 3: Update frontend for processing state</name>
  <files>
    src/hooks/useTranscription.ts
    src/windows/FloatingBar.tsx
  </files>
  <action>
Create `src/hooks/useTranscription.ts`:

```typescript
import { listen } from '@tauri-apps/api/event';
import { useState, useEffect } from 'react';

type TranscriptionStage = 'idle' | 'transcribing' | 'polishing' | 'pasting' | 'complete' | 'error';

interface TranscriptionProgress {
  stage: TranscriptionStage;
  message: string;
}

export function useTranscription() {
  const [stage, setStage] = useState<TranscriptionStage>('idle');
  const [message, setMessage] = useState('');

  useEffect(() => {
    const unlisten = listen<TranscriptionProgress>('transcription-progress', (event) => {
      setStage(event.payload.stage as TranscriptionStage);
      setMessage(event.payload.message);

      // Reset to idle after complete/error
      if (event.payload.stage === 'complete' || event.payload.stage === 'error') {
        setTimeout(() => setStage('idle'), 500);
      }
    });

    return () => { unlisten.then(fn => fn()); };
  }, []);

  const isProcessing = stage !== 'idle';

  return { stage, message, isProcessing };
}
```

Update `src/windows/FloatingBar.tsx`:

1. Import useTranscription hook

2. Get { stage, message, isProcessing } from hook

3. Update the visual state logic:
   - When recording: show wave animation (existing)
   - When isProcessing (transcribing/polishing/pasting): show "Processing..." text or spinner
   - When idle: show grey pill (existing)

4. The floating bar should show:
   - Grey pill when idle
   - Wave animation when recording
   - "Processing..." or pulsing indicator during transcription stages

Keep the existing wave animation for recording. Add a simple processing indicator (could be text "..." that pulses, or a small spinner).

The message from the hook can be displayed if you want more detail, but a simple "Processing..." is fine per CONTEXT.md.
  </action>
  <verify>
`npm run dev` starts without errors. FloatingBar shows different states for idle/recording/processing.
  </verify>
  <done>
Frontend updated: useTranscription hook listens to progress events, FloatingBar shows processing state.
  </done>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 4: End-to-end verification</name>
  <what-built>
Complete transcription pipeline: Option+Space to record -> release -> audio transcribed via Whisper -> polished via GPT-4o-mini -> auto-pasted into active app (or clipboard fallback).
  </what-built>
  <how-to-verify>
1. Start the app: `npm run tauri dev`
2. Open a text editor (TextEdit, VS Code, etc.)
3. Press and hold Option+Space
4. Speak a test phrase: "Um, so like, send the email on Tuesday, no wait, Wednesday"
5. Release Option+Space
6. Watch the floating bar — should show wave during recording, then processing indicator
7. Expected result: "Send the email on Wednesday." appears in the text editor

Also test:
- Double-tap Option+Space for toggle mode
- Test with no speech (should show "No speech detected" notification)
- If paste fails, text should be in clipboard for manual Cmd+V

Note: First paste attempt may prompt for Accessibility permission in System Settings.
  </how-to-verify>
  <resume-signal>Type "approved" if transcription and paste work, or describe issues encountered</resume-signal>
</task>

</tasks>

<verification>
All verification for this plan:

1. `cargo build` succeeds
2. `npm run tauri dev` starts the app
3. Recording triggers transcription pipeline on stop
4. Progress events reach frontend
5. Floating bar shows processing state
6. Text appears in active app OR clipboard with notification
</verification>

<success_criteria>
Phase 2 success criteria from ROADMAP:
1. User's speech is transcribed via Whisper API with proper punctuation
2. Transcription is cleaned by GPT-4o-mini (filler words removed, grammar corrected)
3. Self-corrections in speech are handled ("Tuesday no wait Wednesday" becomes "Wednesday")
4. Polished text is auto-pasted into active application
5. When auto-paste fails, text goes to clipboard with notification
</success_criteria>

<output>
After completion, create `.planning/phases/02-transcription-pipeline/02-03-SUMMARY.md`
</output>
