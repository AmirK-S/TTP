---
phase: 05-ensemble-transcription
plan: 02
type: execute
wave: 2
depends_on: ["05-01"]
files_modified:
  - src-tauri/src/transcription/fusion.rs
  - src-tauri/src/transcription/pipeline.rs
  - src-tauri/src/transcription/mod.rs
autonomous: true

must_haves:
  truths:
    - "LLM receives multiple transcriptions and produces fused output"
    - "Ensemble mode in pipeline uses parallel transcription + fusion"
    - "Single provider result skips fusion (uses normal polish instead)"
  artifacts:
    - path: "src-tauri/src/transcription/fusion.rs"
      provides: "LLM fusion logic combining multiple transcriptions"
      exports: ["fuse_and_polish", "FUSION_SYSTEM_PROMPT"]
    - path: "src-tauri/src/transcription/pipeline.rs"
      provides: "Ensemble mode integration in transcription flow"
      contains: "ensemble_enabled"
  key_links:
    - from: "src-tauri/src/transcription/pipeline.rs"
      to: "transcribe_ensemble"
      via: "function call when ensemble_enabled"
      pattern: "transcribe_ensemble"
    - from: "src-tauri/src/transcription/fusion.rs"
      to: "OpenAI chat API"
      via: "HTTP POST to chat completions"
      pattern: "api.openai.com/v1/chat/completions"
---

<objective>
Create LLM fusion module and integrate ensemble mode into the transcription pipeline.

Purpose: Combine multiple transcription results into a single highest-accuracy output using GPT-4o-mini, and wire ensemble mode into the main transcription flow.
Output: fusion.rs with LLM fusion logic, updated pipeline.rs with ensemble branch.
</objective>

<execution_context>
@/Users/amirkellousidhoum/.claude/get-shit-done/workflows/execute-plan.md
@/Users/amirkellousidhoum/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/05-ensemble-transcription/05-RESEARCH.md
@.planning/phases/05-ensemble-transcription/05-01-SUMMARY.md

# Existing implementation
@src-tauri/src/transcription/polish.rs
@src-tauri/src/transcription/pipeline.rs
@src-tauri/src/transcription/mod.rs
@src-tauri/src/credentials.rs
@src-tauri/src/dictionary/mod.rs
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create fusion.rs with LLM fusion logic</name>
  <files>src-tauri/src/transcription/fusion.rs, src-tauri/src/transcription/mod.rs</files>
  <action>
Create `src-tauri/src/transcription/fusion.rs` with:

1. **FUSION_SYSTEM_PROMPT constant** (from RESEARCH.md):
```rust
pub const FUSION_SYSTEM_PROMPT: &str = r#"You are a transcription expert. You will receive multiple transcriptions of the same audio from different speech recognition systems.

Your task:
1. ANALYZE all transcriptions to identify the most accurate version
2. RESOLVE disagreements by choosing the most likely correct words based on:
   - Agreement across multiple systems (consensus is usually correct)
   - Acoustic plausibility (words that sound similar in speech)
   - Grammatical correctness and natural language flow
   - Context and semantic coherence
3. CLEAN UP the result: remove filler words (um, uh, like), fix grammar, add punctuation
4. PRESERVE the speaker's intent and any language mixing (French/English stays mixed)

Output ONLY the final, cleaned transcription. No explanations."#;
```

2. **build_fusion_prompt function:**
- Takes `&[ProviderResult]` and `&[DictionaryEntry]`
- Builds user prompt with all transcriptions labeled by provider
- Appends dictionary if not empty (same format as polish.rs)
- Returns String

3. **fuse_and_polish async function:**
- Takes `api_key: &str` and `results: &[ProviderResult]`
- Loads dictionary via `get_dictionary()`
- Makes single GPT-4o-mini call with FUSION_SYSTEM_PROMPT and built user prompt
- Uses same HTTP pattern as polish.rs (reqwest, 20s timeout, temp 0.1)
- Returns `Result<String, String>`

4. **Reuse types from polish.rs:**
- Import or duplicate ChatRequest, ChatMessage, ChatResponse, ChatChoice, ChatMessageResponse
- Consider making them pub in polish.rs and importing, OR duplicate (simpler for now)

5. **Update mod.rs:**
- Add `pub mod fusion;`
- Add `pub use fusion::{fuse_and_polish, FUSION_SYSTEM_PROMPT};`
  </action>
  <verify>
Run `cargo check -p ttp` to verify compilation.
Verify the prompt includes all provider results formatted clearly.
  </verify>
  <done>
fusion.rs exists with:
- FUSION_SYSTEM_PROMPT constant for multi-transcription fusion
- build_fusion_prompt function formatting results with dictionary
- fuse_and_polish async function making GPT-4o-mini call
- Proper error handling and response parsing
  </done>
</task>

<task type="auto">
  <name>Task 2: Integrate ensemble mode into pipeline.rs</name>
  <files>src-tauri/src/transcription/pipeline.rs</files>
  <action>
Update `src-tauri/src/transcription/pipeline.rs` to support ensemble mode:

1. **Add imports:**
```rust
use super::ensemble::{transcribe_ensemble, ProviderResult};
use super::fusion::fuse_and_polish;
```

2. **Create process_ensemble helper function:**
```rust
async fn process_ensemble(
    app: &AppHandle,
    audio_path: &str,
) -> Result<String, String> {
    emit_progress(app, "transcribing", "Transcribing (ensemble)...");

    // Get all available API keys
    let openai_key = get_api_key_internal(app).ok().flatten();
    let groq_key = get_groq_api_key_internal(app).ok().flatten();
    let gladia_key = get_gladia_api_key_internal(app).ok().flatten();

    // Count available providers
    let provider_count = [&openai_key, &groq_key, &gladia_key]
        .iter()
        .filter(|k| k.is_some())
        .count();

    if provider_count < 2 {
        return Err("Ensemble requires at least 2 API keys configured".to_string());
    }

    // Run all providers in parallel
    let results = transcribe_ensemble(
        audio_path,
        openai_key.as_deref(),
        groq_key.as_deref(),
        gladia_key.as_deref(),
    ).await?;

    println!("[Ensemble] Got {} provider results", results.len());
    for r in &results {
        println!("[Ensemble] {}: {} chars in {}ms", r.provider, r.text.len(), r.latency_ms);
    }

    // If only one result, fall back to normal polish (skip fusion overhead)
    if results.len() == 1 {
        let text = &results[0].text;
        let settings = get_settings();
        if settings.ai_polish_enabled {
            emit_progress(app, "polishing", "Processing...");
            let openai_key = get_api_key_internal(app)?
                .ok_or("OpenAI API key required for polish")?;
            return polish_text(&openai_key, text).await
                .unwrap_or_else(|_| text.clone());
        }
        return Ok(text.clone());
    }

    // Multiple results: fuse with LLM (includes polish)
    emit_progress(app, "polishing", "Fusing transcriptions...");
    let openai_key = get_api_key_internal(app)?
        .ok_or("OpenAI API key required for ensemble fusion")?;

    fuse_and_polish(&openai_key, &results).await
}
```

3. **Modify process_recording to check ensemble_enabled:**
At the start of process_recording, after getting settings, add ensemble branch:

```rust
let settings = get_settings();

// Check for ensemble mode first
if settings.ensemble_enabled {
    let final_text = process_ensemble(app, &audio_path).await?;

    // Continue with paste stage (existing code)
    // ... paste logic ...

    return Ok(final_text);
}

// Existing single-provider flow continues below...
```

4. **Important:** The paste logic (Stage 3) should be shared between ensemble and single-provider paths. Either:
   - Extract paste logic into a helper function `paste_text(app, text)`, OR
   - Ensure ensemble path returns before paste, then have common paste code after the if/else

Recommended approach: Keep the existing paste logic at the end and have both paths set `final_text`, then continue to shared paste code.

5. **Update the flow:**
```rust
// Determine final text (ensemble or single provider)
let (final_text, raw_text_for_history) = if settings.ensemble_enabled {
    let text = process_ensemble(app, &audio_path).await?;
    (text.clone(), None) // Ensemble already includes polish
} else {
    // Existing single-provider logic (transcribe + polish)
    // ...
    (polished_text, if settings.ai_polish_enabled { Some(raw_text) } else { None })
};

// Stage 3: Paste (shared code)
// ... existing paste logic using final_text ...
```
  </action>
  <verify>
Run `cargo check -p ttp` to verify compilation.
Run `cargo build -p ttp` for full build.
Test manually: Enable ensemble in settings, record audio, verify parallel transcription logs.
  </verify>
  <done>
pipeline.rs updated with:
- process_ensemble helper function for ensemble flow
- Ensemble check at start of process_recording
- Shared paste logic for both paths
- Proper progress events ("Transcribing (ensemble)...", "Fusing transcriptions...")
- Fallback to normal polish when only 1 provider succeeds
  </done>
</task>

</tasks>

<verification>
1. `cargo build -p ttp` succeeds
2. With ensemble_enabled=true, transcription calls all available providers
3. Fusion produces single output from multiple transcriptions
4. Single provider result falls back to normal polish (no fusion)
5. Progress events show ensemble-specific messages
</verification>

<success_criteria>
- fusion.rs exists with FUSION_SYSTEM_PROMPT and fuse_and_polish function
- pipeline.rs checks ensemble_enabled and branches to ensemble flow
- Multiple provider results are fused via LLM
- Single provider result uses normal polish
- Paste logic works for both ensemble and single-provider paths
</success_criteria>

<output>
After completion, create `.planning/phases/05-ensemble-transcription/05-02-SUMMARY.md`
</output>
